docker_shellmetrics:
  type: collection
  ttl: 4h
  removeFields: []
  resumeOnBoot: false
  schedule:
    cronSchedule: "*/10 * * * * *"
    skippable: true
    maxConcurrentRuns: 1
    run:
      mode: run
      timeRangeType: absolute
      expression: "true"
      logLevel: info
      minTaskSize: 1MB
      maxTaskSize: 10MB
    enabled: true
  collector:
    conf:
      shell: /bin/bash
      discoverScript: docker ps --format {{.ID}},{{.Names}}
      collectScript: >-
        #!/bin/sh


        container_id=$(echo $CRIBL_COLLECT_ARG | cut -d , -f 1)

        container_name=$(echo $CRIBL_COLLECT_ARG | cut -d , -f 2)


        run() {
            _out="***CRIBL*** command=${2}"
            if [ -n "${3}" ]; then
                _out="${_out} commver=${3}"
            fi
            _out="${_out} host=${container_name} container_id=${container_id}"


            OLDIFS=${IFS}
            IFS=
            _cmdout=$(eval $1 2>/dev/null)
            _out=$(printf '%s\n%s\n' "${_out}" "${_cmdout}")
            echo ${_out}
            IFS=${OLDIFS}
        }


        run "df -TP" "df" "kilobytes"

        run "df -TPi" "df" "inodes"

        run "cat /proc/diskstats" "cat_proc_diskstats"

        run "cat /proc/stat && sleep 1 && cat /proc/stat" "cat_proc_stat" 

        run "cat /proc/meminfo" "cat_proc_meminfo"

        run "cat /proc/vmstat" "cat_proc_vmstat"

        run "cat /proc/loadavg" "cat_proc_loadavg"

        # run "find /proc -maxdepth 2 -name 'stat' -regex '/proc/[0-9]+/stat' -exec cat {} \; 2>/dev/null" "cat_proc_n_stats"

        run "cat /proc/**/stat" "cat_proc_n_stats"

        run "cat /proc/net/snmp" "cat_proc_net_snmp"

        run "cat /proc/net/dev" "cat_proc_net_dev"

        run "cat /proc/net/tcp" "cat_proc_net_tcp"

        run "cat /proc/net/tcp6" "cat_proc_net_tcp6"

        run "cat /proc/net/udp" "cat_proc_net_udp"

        run "cat /proc/net/udp6" "cat_proc_net_udp6"
    destructive: false
    type: script
  input:
    type: collection
    staleChannelFlushMs: 10000
    sendToRoutes: true
    preprocess:
      disabled: true
    breakerRulesets:
      - Cribl Command
mtr:
  type: collection
  ttl: 4h
  schedule:
    cronSchedule: "*/1 * * * *"
    skippable: true
    run:
      mode: run
      timeRangeType: absolute
      expression: "true"
      logLevel: info
      minTaskSize: 3MB
      maxTaskSize: 1GB
      discoverToRoutes: false
    enabled: true
  collector:
    conf:
      shell: /bin/bash
      discoverScript: echo mtr
      collectScript: mtr --report -c 5 -i 1 --json --no-dns 1.1.1.1 | jq -M -c .
    destructive: false
    type: script
  input:
    type: collection
    staleChannelFlushMs: 10000
    sendToRoutes: true
    preprocess:
      disabled: true
    output: influx
    breakerRulesets:
      - Cribl
speedtest:
  type: collection
  ttl: 4h
  schedule:
    cronSchedule: 0 */4 * * *
    skippable: true
    run:
      mode: run
      timeRangeType: absolute
      expression: "true"
      logLevel: info
      minTaskSize: 3MB
      maxTaskSize: 1GB
      discoverToRoutes: false
    enabled: true
  collector:
    conf:
      shell: /bin/bash
      discoverScript: echo "speedtest"
      collectScript: speedtest --json --server 33560
    destructive: false
    type: script
  input:
    type: collection
    staleChannelFlushMs: 10000
    sendToRoutes: true
    preprocess:
      disabled: true
    breakerRulesets:
      - Cribl
weatherbit:
  type: collection
  ttl: 4h
  removeFields: []
  resumeOnBoot: false
  schedule: {}
  collector:
    conf:
      discovery:
        discoverType: list
        itemList:
          - "60601"
          - "94105"
          - "10022"
          - "20500"
          - "90038"
      collectMethod: get
      authentication: none
      collectUrl: "`https://api.weatherbit.io/v2.0/current?postal_code=${id}&units=I&key=\
        0018fca125f245198919f5e087f6cb43`"
    destructive: false
    type: rest
  input:
    type: collection
    staleChannelFlushMs: 10000
    sendToRoutes: false
    preprocess:
      disabled: true
    pipeline: process_weather
    output: splunk-metrics
    metadata:
      - name: sourcetype
        value: "`weather`"
      - name: index
        value: "`cribl`"
salesforce_status:
  type: collection
  ttl: 4h
  removeFields: []
  resumeOnBoot: false
  schedule:
    cronSchedule: "*/5 * * * *"
    skippable: true
    maxConcurrentRuns: 1
    run:
      mode: run
      timeRangeType: absolute
      expression: "true"
      logLevel: info
      minTaskSize: 1MB
      maxTaskSize: 10MB
    enabled: true
  collector:
    conf:
      discovery:
        discoverType: list
        itemList:
          - NA134
          - NA111
          - NA135
      collectMethod: get
      authentication: none
      collectUrl: "`https://api.status.salesforce.com/v1/instances/${id}/status?childProd\
        ucts=false`"
    destructive: false
    type: rest
  input:
    type: collection
    staleChannelFlushMs: 10000
    sendToRoutes: false
    preprocess:
      disabled: true
    pipeline: sfdc_status
    output: influxdb
    metadata:
      - name: sfdc_instance
        value: "`${__collectible.id}`"
      - name: sourcetype
        value: "`sfdc_status`"
      - name: index
        value: "`cribl`"
      - name: source
        value: "`SFDC_instance_status_api`"
earthquakes_last_hour:
  type: collection
  ttl: 4h
  removeFields: []
  resumeOnBoot: false
  schedule: {}
  collector:
    conf:
      discovery:
        discoverType: none
      collectMethod: get
      authentication: none
      collectUrl: "`https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.ge\
        ojson`"
    destructive: false
    type: rest
  input:
    type: collection
    staleChannelFlushMs: 10000
    sendToRoutes: false
    preprocess:
      disabled: true
    metadata:
      - name: sourcetype
        value: "`usgs_earthquakes`"
      - name: index
        value: "`cribl`"
    breakerRulesets:
      - Cribl - Do Not Break Ruleset
    pipeline: usgs_earthquakes
    output: splunk-metrics
